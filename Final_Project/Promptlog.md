"Write a Python code snippet using the requests library that downloads a monthly On-Time Performance ZIP file from BTS.gov. The function should take year and month as arguments, build the correct URL for the BTS On-Time Reporting data, download the ZIP file to a local path (such as '{year}-{month}.zip'), and raise an error if the HTTP request fails."

"Write a Python code snippet that takes a cleaned CSV file of flight data and loads it into a BigQuery table named flights_data in my project. Use the google-cloud-bigquery library, configure a LoadJobConfig with CSV as the source format, load the file from Google Cloud Storage, wait for the job to finish, and print a confirmation when the load succeeds."

"Combine the previous Extract and Load steps into a single Python function called process_month(year, month, bucket_name) that: (1) downloads the monthly BTS flight data ZIP file, (2) unzips it to locate the CSV, (3) performs basic cleaning on each line (removing trailing commas and double quotes), (4) saves the cleaned CSV to a new file, and (5) uploads that cleaned CSV to a GCS bucket path such as data/flightsETL/. Use requests, zipfile, file I/O, and either gsutil via subprocess or the Python GCS client. Include print statements describing each step."

"Rewrite my Python ETL function to add robust error handling: wrap the HTTP download in a try...except block that catches requests.exceptions.RequestException, handle zipfile.BadZipFile when unzipping, and handle subprocess.CalledProcessError when running gsutil. Each except block should log a clear error message and ensure the function exits gracefully without crashing. Show the full updated function."
